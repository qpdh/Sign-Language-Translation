{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a20bbc77",
   "metadata": {},
   "source": [
    "# 데이터 to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3f6e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6be2404",
   "metadata": {},
   "source": [
    "## 2. Path 설정\n",
    "1. 숫자\n",
    "2. 영어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb1da04",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir = './Sign-Language-Digits-Dataset-master/Sign Language for Numbers/'\n",
    "#path_dir = './dataset/'\n",
    "# 0 ... 9 손가락 숫자\n",
    "path_type = [i for i in range(10)]\n",
    "decimal_path_type = [i for i in range(10)]\n",
    "alphabet_path_type = [i for i in range(97,123)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7551747b",
   "metadata": {},
   "source": [
    "## 3. 데이터 처리 형식 지정\n",
    "- 각도 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539a694f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint_to_angle(landmark):\n",
    "    \n",
    "    # 21 x,y,z np array 생성\n",
    "    joint = np.zeros((21,3))\n",
    "    \n",
    "    for j,lm in enumerate(landmark.landmark):\n",
    "        joint[j] = [lm.x,lm.y,lm.z]\n",
    "    \n",
    "    joint1=  joint[[0, 1, 2, 3, 0, 5, 6, 7, 0, 9, 10, 11, 0, 13, 14, 15, 0, 17, 18, 19],:]\n",
    "    joint2 = joint[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],:]\n",
    "\n",
    "    # 각 좌표의 벡터를 구함\n",
    "    vec = joint1 - joint2\n",
    "\n",
    "    vec = vec / np.linalg.norm(vec,axis=1)[:,np.newaxis]\n",
    "    # 기존 벡터 변환\n",
    "#     compareV1 = vec[[0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 16, 17],:]\n",
    "#     compareV2 = vec[[1, 2, 3, 5, 6, 7 ,9, 10, 11, 13, 14, 15, 17, 18, 19],:]\n",
    "\n",
    "    # 새로운 벡터 변환\n",
    "    compareV1 = vec[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 16, 17, 17, 18],:]\n",
    "    compareV2 = vec[[1, 2, 3, 7, 5, 6, 7, 9, 9, 10, 11, 13, 14, 15, 17, 18, 19, 19],:]\n",
    "    angle = np.arccos(np.einsum('nt,nt->n',compareV1,compareV2))\n",
    "\n",
    "    angle = np.degrees(angle)\n",
    "    \n",
    "    return angle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85812d03",
   "metadata": {},
   "source": [
    "## 4. 데이터 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df298e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_data(path_type):\n",
    "    # For static images:\n",
    "    # TODO 여기 안에 처리되는 데이터를, 배열로 저장해서 CSV 형태로 저장\n",
    "\n",
    "    landmarks_list = list(list())\n",
    "\n",
    "    # 0 ~ 20\n",
    "    # x, y, z\n",
    "    # 63\n",
    "    # 63 + target[0 ~ 9]\n",
    "\n",
    "    # 데이터가 0~9 까지 각각 200개씩\n",
    "    # 최댓값은 2000개\n",
    "\n",
    "    for t in path_type:\n",
    "        IMAGE_FILES = list()\n",
    "        # 불러오는 위치\n",
    "        from_path = path_dir + str(t) + '/'\n",
    "\n",
    "        # 파일 불러오기\n",
    "        file_list = os.listdir(from_path)\n",
    "        # 확장자가 jpg 인 모든 파일을 불러온다.\n",
    "        IMAGE_FILES+=[from_path+ file for file in file_list if file.endswith('.JPG') or file.endswith('.jpg')]\n",
    "\n",
    "        with mp_hands.Hands(static_image_mode = True,max_num_hands = 1,min_detection_confidence=0.5) as hands:\n",
    "            for idx, file in enumerate(IMAGE_FILES):\n",
    "                #print(file)\n",
    "\n",
    "                idx_landmarks = []\n",
    "\n",
    "                image = cv2.flip(cv2.imread(file), 0)\n",
    "\n",
    "                result = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "                if not result.multi_hand_landmarks:\n",
    "                    continue\n",
    "\n",
    "                image_hegiht, image_width, _ =image.shape\n",
    "\n",
    "                annotated_image = image.copy()\n",
    "                for hand_landmarks in result.multi_hand_landmarks:\n",
    "                    print('now : ',t)\n",
    "                    #landmarks_list.append(np.append(joint_to_angle(hand_landmarks),int(t)))\n",
    "                    landmarks_list.append(np.append(joint_to_angle(hand_landmarks),t))\n",
    "                \n",
    "    return landmarks_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09f8cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks_list = image_to_data(decimal_path_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e8bc1c",
   "metadata": {},
   "source": [
    "## 5. 차원 수 만큼 할당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f90c11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d : 차원 수\n",
    "def df_to_csv(d,file_name):\n",
    "    df_columns = []\n",
    "    for i in range(d):\n",
    "        df_columns.append(i)\n",
    "\n",
    "\n",
    "    print(df_columns)\n",
    "\n",
    "    df_columns.append('target')\n",
    "\n",
    "    # print(landmarks_list)\n",
    "    df = pd.DataFrame(landmarks_list,columns=df_columns)\n",
    "    df.columns\n",
    "    print(df)\n",
    "    df.to_csv(file_name)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71312990",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_to_csv(18,'output_digit.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7426ce32",
   "metadata": {},
   "source": [
    "## 6. CSV 로 내보내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7d4050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f211e3d8",
   "metadata": {},
   "source": [
    "# CSV to TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7613109a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7bab59",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_URL = './output_alpha.csv'\n",
    "\n",
    "data = pd.read_csv(TRAIN_DATA_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52658f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = train_test_split(data, \n",
    "                 test_size=1/10,\n",
    "                stratify=data['target'],\n",
    "                random_state=20210918)\n",
    "\n",
    "target_train = data_train.pop('target')\n",
    "target_test = data_test.pop('target')\n",
    "\n",
    "data_train.pop('Unnamed: 0')\n",
    "data_test.pop('Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad8eece",
   "metadata": {},
   "source": [
    "## 모델 생성\n",
    "- 시작 값(차원 수)\n",
    "- 끝 값(분류할 차원 수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec56781e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_model4():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(64,activation='relu',input_shape=(15,)))\n",
    "    model.add(tf.keras.layers.Dense(64,activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(32,activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(26,activation='softmax'))\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(optimizer='Adam',\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['categorical_accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3373ba",
   "metadata": {},
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5319fa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = get_compiled_model()\n",
    "# model.fit(dataset_train,epochs=10)\n",
    "model = get_compiled_model4()\n",
    "# model.summary()\n",
    "\n",
    "# model.compile(optimizer=tf.optimizers.Adam(),\n",
    "#               loss='sparse_categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#(x_train, y_train),(x_test,y_test)=tf.keras.datasets.mnist.load_data()\n",
    "print(target_train)\n",
    "t = []\n",
    "for a in target_train:\n",
    "    tmplist = list()\n",
    "    for i in range(26):\n",
    "        tmplist.append(0)\n",
    "    tmplist[ord(a)-97] = 1\n",
    "    t.append(tmplist)\n",
    "print(t)\n",
    "\n",
    "model.fit(np.array(data_train),\n",
    "          np.array(t), epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccd1c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('OutputModel_Alpha')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e1f31f",
   "metadata": {},
   "source": [
    "# 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5cc771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# \n",
    "\n",
    "sequence = []\n",
    "sentence = []\n",
    "threshold = 0.4\n",
    "actions=['0','1','2','3','4','5','6','7','8','9']\n",
    "actions_alpha=[chr(i) for i in range(65,91)]\n",
    "\n",
    "#model = tensorflow.keras.models.load_model('./OutputModel_Alpha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c388444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint_to_angle(landmark):\n",
    "    \n",
    "    # 21 x,y,z np array 생성\n",
    "    joint = np.zeros((21,3))\n",
    "    \n",
    "    for j,lm in enumerate(landmark.landmark):\n",
    "        joint[j] = [lm.x,lm.y,lm.z]\n",
    "    \n",
    "    joint1=  joint[[0, 1, 2, 3, 0, 5, 6, 7, 0, 9, 10, 11, 0, 13, 14, 15, 0, 17, 18, 19],:]\n",
    "    joint2 = joint[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],:]\n",
    "\n",
    "    # 각 좌표의 벡터를 구함\n",
    "    vec = joint1 - joint2\n",
    "\n",
    "    vec = vec / np.linalg.norm(vec,axis=1)[:,np.newaxis]\n",
    "    \n",
    "    compareV1 = vec[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 16, 17, 17,18],:]\n",
    "    compareV2 = vec[[1, 2, 3, 7, 5, 6, 7, 9, 9, 10, 11, 13, 14, 15, 17, 18, 19,19],:]\n",
    "#     compareV1 = vec[[0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 16, 17],:]\n",
    "#     compareV2 = vec[[1, 2, 3, 5, 6, 7 ,9, 10, 11, 13, 14, 15, 17, 18, 19],:]\n",
    "    angle = np.arccos(np.einsum('nt,nt->n',compareV1,compareV2))\n",
    "\n",
    "    angle = np.degrees(angle)\n",
    "    \n",
    "    return angle\n",
    "\n",
    "def joint_to_angle_alpha(landmark):\n",
    "    \n",
    "    # 21 x,y,z np array 생성\n",
    "    joint = np.zeros((21,3))\n",
    "    \n",
    "    for j,lm in enumerate(landmark.landmark):\n",
    "        joint[j] = [lm.x,lm.y,lm.z]\n",
    "    \n",
    "    joint1=  joint[[0, 1, 2, 3, 0, 5, 6, 7, 0, 9, 10, 11, 0, 13, 14, 15, 0, 17, 18, 19],:]\n",
    "    joint2 = joint[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],:]\n",
    "\n",
    "    # 각 좌표의 벡터를 구함\n",
    "    vec = joint1 - joint2\n",
    "\n",
    "    vec = vec / np.linalg.norm(vec,axis=1)[:,np.newaxis]\n",
    "    \n",
    "#     compareV1 = vec[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 16, 17, 17,18],:]\n",
    "#     compareV2 = vec[[1, 2, 3, 7, 5, 6, 7, 9, 9, 10, 11, 13, 14, 15, 17, 18, 19,19],:]\n",
    "    compareV1 = vec[[0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 16, 17],:]\n",
    "    compareV2 = vec[[1, 2, 3, 5, 6, 7 ,9, 10, 11, 13, 14, 15, 17, 18, 19],:]\n",
    "    angle = np.arccos(np.einsum('nt,nt->n',compareV1,compareV2))\n",
    "\n",
    "    angle = np.degrees(angle)\n",
    "    \n",
    "    return angle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8d7d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_URL = './output_digit.csv'\n",
    "\n",
    "file = np.genfromtxt(TRAIN_DATA_URL,delimiter=',')\n",
    "file = np.delete(file,0,axis=1)\n",
    "file = np.delete(file,0,axis=0)\n",
    "angleFile = file[1:,:-1]\n",
    "labelFile = file[1:,-1]\n",
    "\n",
    "angle = angleFile.astype(np.float32)\n",
    "label = labelFile.astype(np.float32)\n",
    "knn = cv2.ml.KNearest_create()\n",
    "knn.train(angle,cv2.ml.ROW_SAMPLE,label)\n",
    "\n",
    "file_alpha = np.genfromtxt('./DataSet.txt',delimiter=',')\n",
    "angleFile_alpha = file_alpha[:,:-1]\n",
    "labelFile_alpha = file_alpha[:,-1]                         \n",
    "\n",
    "angle_alpha = angleFile_alpha.astype(np.float32)\n",
    "label_alpha = labelFile_alpha.astype(np.float32)\n",
    "knn_alpha = cv2.ml.KNearest_create()\n",
    "knn_alpha.train(angle_alpha,cv2.ml.ROW_SAMPLE,label_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8284816",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(label_alpha)\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2319cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(angle_alpha))\n",
    "print(angle[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e1b671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 숫자\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "recognizeDelay = 0.5\n",
    "start_time = time.time()\n",
    "premotion = 0\n",
    "\n",
    "with mp_hands.Hands(\n",
    "    min_detection_confidence=0.5, \n",
    "    min_tracking_confidence=0.5) as hands:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        \n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            # If loading a video, use 'break' instead of 'continue'.\n",
    "            continue\n",
    "                       #cv2.flip(image, 1)\n",
    "        imgRGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        #image.flags.writeable = False\n",
    "        results = hands.process(imgRGB)\n",
    "        \n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                input_data = joint_to_angle(hand_landmarks)\n",
    "                \n",
    "                data = np.array([input_data],dtype=np.float32)\n",
    "                        \n",
    "                res,results,neighbours,dist = knn.findNearest(data,3)\n",
    "                \n",
    "                # 손 landmark 그리기\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image,\n",
    "                    hand_landmarks,\n",
    "                    mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                index = chr(int(results[0][0])+48)\n",
    "                if index in actions:\n",
    "                    \n",
    "                    #checkmotion = actions_alpha[np.argmax(res)]\n",
    "                    if len(sentence) > 0:\n",
    "                        if index != sentence[-1]:\n",
    "                            if index != premotion:\n",
    "                                premotion = index\n",
    "                                start_time = time.time()\n",
    "\n",
    "                            else:\n",
    "                                # 시간이 1초가 넘어가면 삽입\n",
    "                                if time.time() - start_time > recognizeDelay:\n",
    "                                    sentence.append(index)     \n",
    "    #                         if actions[np.argmax(res)] != sentence[-1]:\n",
    "    #                             # 이전 제스쳐와 다르면 시간재기                                 \n",
    "                    else:\n",
    "                        sentence.append(index)\n",
    "\n",
    "                # 5개가 넘어가면 삭제\n",
    "                if len(sentence) > 10:\n",
    "                    sentence = sentence[-10:]\n",
    "\n",
    "                # 사각형으로 그리기\n",
    "                cv2.rectangle(image,(0,0),(640,40),(245,117,16),-1)\n",
    "                cv2.putText(image, ' '.join(sentence),(3,30),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255),2,cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "        # 종료 조건\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2154aaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 영어\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "recognizeDelay = 0.5\n",
    "start_time = time.time()\n",
    "premotion = 0\n",
    "\n",
    "with mp_hands.Hands(\n",
    "    min_detection_confidence=0.5, \n",
    "    min_tracking_confidence=0.5) as hands:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        \n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            # If loading a video, use 'break' instead of 'continue'.\n",
    "            continue\n",
    "                       #cv2.flip(image, 1)\n",
    "        imgRGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        #image.flags.writeable = False\n",
    "        results = hands.process(imgRGB)\n",
    "        \n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:        \n",
    "                input_data = joint_to_angle_alpha(hand_landmarks)\n",
    "                \n",
    "                data = np.array([input_data],dtype=np.float32)\n",
    "                \n",
    "                print(np.shape(data))\n",
    "                \n",
    "                res,results,neighbours,dist = knn_alpha.findNearest(data,3)\n",
    "                \n",
    "                # 손 landmark 그리기\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image,\n",
    "                    hand_landmarks,\n",
    "                    mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                index = chr(int(results[0][0])+65)\n",
    "                print(index)\n",
    "                print(index in actions_alpha)\n",
    "                if index in actions_alpha:\n",
    "                    \n",
    "                    #checkmotion = actions_alpha[np.argmax(res)]\n",
    "                    if len(sentence) > 0:\n",
    "                        if index != sentence[-1]:\n",
    "                            if index != premotion:\n",
    "                                premotion = index\n",
    "                                start_time = time.time()\n",
    "\n",
    "                            else:\n",
    "                                # 시간이 1초가 넘어가면 삽입\n",
    "                                if time.time() - start_time > recognizeDelay:\n",
    "                                    sentence.append(index)     \n",
    "    #                         if actions[np.argmax(res)] != sentence[-1]:\n",
    "    #                             # 이전 제스쳐와 다르면 시간재기                                 \n",
    "                    else:\n",
    "                        sentence.append(index)\n",
    "\n",
    "                # 5개가 넘어가면 삭제\n",
    "                if len(sentence) > 10:\n",
    "                    sentence = sentence[-10:]\n",
    "\n",
    "                # 사각형으로 그리기\n",
    "                cv2.rectangle(image,(0,0),(640,40),(245,117,16),-1)\n",
    "                cv2.putText(image, ' '.join(sentence),(3,30),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255),2,cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "        # 종료 조건\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2951289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예전거\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "recognizeDelay = 0.5\n",
    "start_time = time.time()\n",
    "premotion = 0\n",
    "\n",
    "with mp_hands.Hands(\n",
    "    min_detection_confidence=0.5, \n",
    "    min_tracking_confidence=0.5) as hands:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        \n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            # If loading a video, use 'break' instead of 'continue'.\n",
    "            continue\n",
    "                       #cv2.flip(image, 1)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        #image.flags.writeable = False\n",
    "        results = hands.process(image)\n",
    "        \n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:        \n",
    "                input_data = np.expand_dims(joint_to_angle(hand_landmarks),axis=0)\n",
    "\n",
    "                res = model.predict(input_data)\n",
    "                #print(actions[np.argmax(res)])\n",
    "                \n",
    "                # 손 landmark 그리기\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image,\n",
    "                    hand_landmarks,\n",
    "                    mp_hands.HAND_CONNECTIONS,\n",
    "                    mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                    mp_drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "                if np.argmax(res) > threshold:\n",
    "                    checkmotion = actions_alpha[np.argmax(res)]\n",
    "                    \n",
    "                    if len(sentence) > 0:\n",
    "                        if checkmotion != sentence[-1]:\n",
    "                            if checkmotion != premotion:\n",
    "                                premotion = checkmotion\n",
    "                                start_time = time.time()\n",
    "\n",
    "                            else:\n",
    "                                # 시간이 1초가 넘어가면 삽입\n",
    "                                if time.time() - start_time > recognizeDelay:\n",
    "                                    sentence.append(actions_alpha[np.argmax(res)])     \n",
    "    #                         if actions[np.argmax(res)] != sentence[-1]:\n",
    "    #                             # 이전 제스쳐와 다르면 시간재기                                 \n",
    "                    else:\n",
    "                        sentence.append(actions_alpha[np.argmax(res)])\n",
    "\n",
    "                # 5개가 넘어가면 삭제\n",
    "                if len(sentence) > 10:\n",
    "                    sentence = sentence[-10:]\n",
    "\n",
    "                # 사각형으로 그리기\n",
    "                cv2.rectangle(image,(0,0),(640,40),(245,117,16),-1)\n",
    "                cv2.putText(image, ' '.join(sentence),(3,30),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255),2,cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "        # 종료 조건\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
